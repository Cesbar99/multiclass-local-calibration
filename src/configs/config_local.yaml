defaults:
  - _self_
  - models: calibrator #mlp
  - dataset: synthetic

# Global parameters
seed: 42
use_wandb: True
resume_training: False
offline: False
device: cuda
cuda_device: 0

# Checkpoints
checkpoint:
  data: synthetic
  seed: 42
  epochs: 30
  temperature: 1.0
  num_classes: 5
  num_features: 10

# main commands
pretrain: False
test: False
calibrate: True
exp_name: 
data: 'synthetic'
calibration_method: "local_calibration"

# synthetic data model
#init_logits_scaling: 1.

# weight and bias
wandb_entity: cesare-barbera-university-of-trento
wandb_project: calibration-experiments
wandb_id:
use_wand: True

# testing and calibration metrics
n_bins_calibration_metrics: 15
save_path_calibration_plots: /home/barbera/calibration/localibration/results/plots/

# default behaviour for batch size
batch_size_map:
  pretraining: 32
  calibration: 512



